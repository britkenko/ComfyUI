{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/britkenko/ComfyUI/blob/master/FINAL_trainerr_XL_ipynb_jeongseon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slgjeYgd6pWp"
      },
      "source": [
        "[![visitor][visitor-badge]][visitor-stats]\n",
        "[![ko-fi][ko-fi-badge]][ko-fi-link]\n",
        "\n",
        "# **Kohya LoRA Trainer XL**\n",
        "A Colab Notebook For SDXL LoRA Training (Fine-tuning Method)\n",
        "\n",
        "[visitor-badge]: https://api.visitorbadge.io/api/visitors?path=Kohya%20LoRA%20Trainer%20XL&label=Visitors&labelColor=%2334495E&countColor=%231ABC9C&style=flat&labelStyle=none\n",
        "[visitor-stats]: https://visitorbadge.io/status?path=Kohya%20LoRA%20Trainer%20XL\n",
        "[ko-fi-badge]: https://img.shields.io/badge/Support%20me%20on%20Ko--fi-F16061?logo=ko-fi&logoColor=white&style=flat\n",
        "[ko-fi-link]: https://ko-fi.com/linaqruf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MxF9feWshAp"
      },
      "source": [
        "| Notebook Name | Description | Link |\n",
        "| --- | --- | --- |\n",
        "| [Kohya LoRA Trainer XL](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-trainer-XL.ipynb) | LoRA Training | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-trainer-XL.ipynb) |\n",
        "| [Kohya Trainer XL](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-trainer-XL.ipynb) | Native Training | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-trainer-XL.ipynb) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIbwGFkJ0nTx"
      },
      "source": [
        "<hr>\n",
        "<h4><font color=\"#4a90e2\"><b>NEWS:</b></font> <i>Colab's free-tier users can now train SDXL LoRA using the diffusers format instead of checkpoint as a pretrained model.</i></h4>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTVqCAgSmie4"
      },
      "source": [
        "# **I. Prepare Environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_2K4wT3zMp_",
        "outputId": "eb63fcae-12ce-4fa2-e725-82311c6c2056",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torch 2.2.2\n",
            "Uninstalling torch-2.2.2:\n",
            "  Successfully uninstalled torch-2.2.2\n",
            "Found existing installation: torchaudio 2.2.2\n",
            "Uninstalling torchaudio-2.2.2:\n",
            "  Successfully uninstalled torchaudio-2.2.2\n",
            "Found existing installation: torchvision 0.17.2\n",
            "Uninstalling torchvision-0.17.2:\n",
            "  Successfully uninstalled torchvision-0.17.2\n",
            "Found existing installation: torchtext 0.17.2\n",
            "Uninstalling torchtext-0.17.2:\n",
            "  Successfully uninstalled torchtext-0.17.2\n",
            "Found existing installation: torchdata 0.7.1\n",
            "Uninstalling torchdata-0.7.1:\n",
            "  Successfully uninstalled torchdata-0.7.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch\n",
            "  Using cached torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchaudio\n",
            "  Using cached torchaudio-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting torchvision\n",
            "  Using cached torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting torchtext\n",
            "  Using cached torchtext-0.17.2-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting torchdata\n",
            "  Using cached torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "Using cached torchaudio-2.2.2-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "Using cached torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "Using cached torchtext-0.17.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "Using cached torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "Installing collected packages: torch, torchvision, torchtext, torchdata, torchaudio\n",
            "Successfully installed torch-2.2.2 torchaudio-2.2.2 torchdata-0.7.1 torchtext-0.17.2 torchvision-0.17.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.25.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.25.2)\n",
            "Requirement already satisfied: torch==2.2.2 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->xformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->xformers) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.2->xformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2->xformers) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Requirement already satisfied: jax==0.4.23 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]==0.4.23) (0.4.23)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax==0.4.23->jax[cuda12_pip]==0.4.23) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax==0.4.23->jax[cuda12_pip]==0.4.23) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax==0.4.23->jax[cuda12_pip]==0.4.23) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax==0.4.23->jax[cuda12_pip]==0.4.23) (1.11.4)\n",
            "\u001b[33mWARNING: jax 0.4.23 does not provide the extra 'cuda12-pip'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: jaxlib==0.4.23+cuda12.cudnn89 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]==0.4.23) (0.4.23+cuda12.cudnn89)\n",
            "Collecting nvidia-cublas-cu12>=12.2.5.6 (from jax[cuda12_pip]==0.4.23)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12>=12.2.142 (from jax[cuda12_pip]==0.4.23)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cuda-nvcc-cu12>=12.2.140 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]==0.4.23) (12.4.131)\n",
            "Collecting nvidia-cuda-runtime-cu12>=12.2.140 (from jax[cuda12_pip]==0.4.23)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12>=8.9 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]==0.4.23) (8.9.2.26)\n",
            "Collecting nvidia-cufft-cu12>=11.0.8.103 (from jax[cuda12_pip]==0.4.23)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12>=11.5.2 (from jax[cuda12_pip]==0.4.23)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12>=12.1.2.141 (from jax[cuda12_pip]==0.4.23)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12>=2.18.3 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]==0.4.23) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12>=12.2 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]==0.4.23) (12.4.127)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Installing collected packages: nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
            "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
            "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
            "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.2.2 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.4.5.8 which is incompatible.\n",
            "torch 2.2.2 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.4.127 which is incompatible.\n",
            "torch 2.2.2 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.4.127 which is incompatible.\n",
            "torch 2.2.2 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.1.3 which is incompatible.\n",
            "torch 2.2.2 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.1.9 which is incompatible.\n",
            "torch 2.2.2 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.3.1.170 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cufft-cu12-11.2.1.3 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: scvi-tools in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: anndata>=0.7.5 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.10.7)\n",
            "Requirement already satisfied: docrep>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.3.2)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.8.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.4.23)\n",
            "Requirement already satisfied: jaxlib>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.4.23+cuda12.cudnn89)\n",
            "Requirement already satisfied: lightning<2.2,>=2.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (2.1.4)\n",
            "Requirement already satisfied: ml-collections>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.1.1)\n",
            "Requirement already satisfied: mudata>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.2.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (1.25.2)\n",
            "Requirement already satisfied: numpyro>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.14.0)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.2.2)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (2.0.3)\n",
            "Requirement already satisfied: pyro-ppl>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (1.9.0)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (13.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (2.2.2)\n",
            "Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (1.3.2)\n",
            "Requirement already satisfied: tqdm>=4.56.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (4.66.2)\n",
            "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /usr/local/lib/python3.10/dist-packages (from anndata>=0.7.5->scvi-tools) (1.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata>=0.7.5->scvi-tools) (1.2.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from anndata>=0.7.5->scvi-tools) (8.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from anndata>=0.7.5->scvi-tools) (24.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from docrep>=0.3.2->scvi-tools) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.4->scvi-tools) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.4->scvi-tools) (3.3.0)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning<2.2,>=2.0->scvi-tools) (6.0.1)\n",
            "Requirement already satisfied: fsspec<2025.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (2023.6.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning<2.2,>=2.0->scvi-tools) (0.11.2)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning<2.2,>=2.0->scvi-tools) (4.11.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning<2.2,>=2.0->scvi-tools) (1.9.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from ml-collections>=0.1.1->scvi-tools) (1.4.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml-collections>=0.1.1->scvi-tools) (21.6.0)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from numpyro>=0.12.1->scvi-tools) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->scvi-tools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->scvi-tools) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->scvi-tools) (2024.1)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.6.0->scvi-tools) (0.1.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->scvi-tools) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->scvi-tools) (2.16.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.2->scvi-tools) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.2->scvi-tools) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scvi-tools) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scvi-tools) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scvi-tools) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scvi-tools) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scvi-tools) (12.1.105)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->scvi-tools)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->scvi-tools)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scvi-tools) (8.9.2.26)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->scvi-tools)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->scvi-tools)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scvi-tools) (10.3.2.106)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->scvi-tools)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->scvi-tools)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scvi-tools) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scvi-tools) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scvi-tools) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->scvi-tools) (12.4.127)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->scvi-tools) (1.0.8)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->scvi-tools) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->scvi-tools) (0.1.45)\n",
            "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax->scvi-tools) (0.1.86)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax->scvi-tools) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.8.0->lightning<2.2,>=2.0->scvi-tools) (67.7.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->scvi-tools) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->scvi-tools) (2.1.5)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->scvi-tools) (1.7.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->scvi-tools) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->scvi-tools) (3.20.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->scvi-tools) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (4.0.3)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->scvi-tools) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->scvi-tools) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (2024.2.2)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Installing collected packages: nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cufft-cu12-11.0.2.54 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "lz4 is already the newest version (1.9.3-2build2).\n",
            "aria2 is already the newest version (1.36.0-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip3 uninstall --yes torch torchaudio torchvision torchtext torchdata\n",
        "!pip3 install torch torchaudio torchvision torchtext torchdata\n",
        "!pip install xformers\n",
        "!pip install \"jax[cuda12_pip]==0.4.23\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "!pip install scvi-tools\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import time\n",
        "import requests\n",
        "import torch\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "from google.colab import drive\n",
        "\n",
        "%store -r\n",
        "\n",
        "# root_dir\n",
        "root_dir          = \"/content\"\n",
        "drive_dir         = os.path.join(root_dir, \"drive/MyDrive\")\n",
        "deps_dir          = os.path.join(root_dir, \"deps\")\n",
        "repo_dir          = os.path.join(root_dir, \"kohya-trainer\")\n",
        "training_dir      = os.path.join(root_dir, \"LoRA\")\n",
        "pretrained_model  = os.path.join(root_dir, \"pretrained_model\")\n",
        "vae_dir           = os.path.join(root_dir, \"vae\")\n",
        "lora_dir          = os.path.join(root_dir, \"network_weight\")\n",
        "repositories_dir  = os.path.join(root_dir, \"repositories\")\n",
        "config_dir        = os.path.join(training_dir, \"config\")\n",
        "tools_dir         = os.path.join(repo_dir, \"tools\")\n",
        "finetune_dir      = os.path.join(repo_dir, \"finetune\")\n",
        "accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "\n",
        "for store in [\"root_dir\", \"repo_dir\", \"training_dir\", \"pretrained_model\", \"vae_dir\", \"repositories_dir\", \"accelerate_config\", \"tools_dir\", \"finetune_dir\", \"config_dir\"]:\n",
        "    with capture.capture_output() as cap:\n",
        "        %store {store}\n",
        "        del cap\n",
        "\n",
        "repo_dict = {\n",
        "    \"qaneel/kohya-trainer (forked repo, stable, optimized for colab use)\" : \"https://github.com/qaneel/kohya-trainer\",\n",
        "    \"kohya-ss/sd-scripts (original repo, latest update)\"                    : \"https://github.com/kohya-ss/sd-scripts\",\n",
        "}\n",
        "\n",
        "repository        = \"qaneel/kohya-trainer (forked repo, stable, optimized for colab use)\" #@param [\"qaneel/kohya-trainer (forked repo, stable, optimized for colab use)\", \"kohya-ss/sd-scripts (original repo, latest update)\"] {allow-input: true}\n",
        "repo_url          = repo_dict[repository]\n",
        "branch            = \"main\"  # @param {type: \"string\"}\n",
        "output_to_drive   = True  # @param {type: \"boolean\"}\n",
        "\n",
        "def clone_repo(url, dir, branch):\n",
        "    if not os.path.exists(dir):\n",
        "       !git clone -b {branch} {url} {dir}\n",
        "\n",
        "def mount_drive(dir):\n",
        "    output_dir      = os.path.join(training_dir, \"output\")\n",
        "\n",
        "    if output_to_drive:\n",
        "        if not os.path.exists(drive_dir):\n",
        "            drive.mount(os.path.dirname(drive_dir))\n",
        "        output_dir  = os.path.join(drive_dir, \"kohya-trainer/output\")\n",
        "\n",
        "    return output_dir\n",
        "\n",
        "def setup_directories():\n",
        "    global output_dir\n",
        "\n",
        "    output_dir      = mount_drive(drive_dir)\n",
        "\n",
        "    for dir in [training_dir, config_dir, pretrained_model, vae_dir, repositories_dir, output_dir]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "def pastebin_reader(id):\n",
        "    if \"pastebin.com\" in id:\n",
        "        url = id\n",
        "        if 'raw' not in url:\n",
        "                url = url.replace('pastebin.com', 'pastebin.com/raw')\n",
        "    else:\n",
        "        url = \"https://pastebin.com/raw/\" + id\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    lines = response.text.split('\\n')\n",
        "    return lines\n",
        "\n",
        "def install_repository():\n",
        "    global infinite_image_browser_dir, voldy, discordia_archivum_dir\n",
        "\n",
        "    _, voldy = pastebin_reader(\"kq6ZmHFU\")[:2]\n",
        "\n",
        "    infinite_image_browser_url  = f\"https://github.com/zanllp/{voldy}-infinite-image-browsing.git\"\n",
        "    infinite_image_browser_dir  = os.path.join(repositories_dir, f\"infinite-image-browsing\")\n",
        "    infinite_image_browser_deps = os.path.join(infinite_image_browser_dir, \"requirements.txt\")\n",
        "\n",
        "    discordia_archivum_url = \"https://github.com/Linaqruf/discordia-archivum\"\n",
        "    discordia_archivum_dir = os.path.join(repositories_dir, \"discordia-archivum\")\n",
        "    discordia_archivum_deps = os.path.join(discordia_archivum_dir, \"requirements.txt\")\n",
        "\n",
        "    clone_repo(infinite_image_browser_url, infinite_image_browser_dir, \"main\")\n",
        "    clone_repo(discordia_archivum_url, discordia_archivum_dir, \"main\")\n",
        "\n",
        "    !pip install -q --upgrade -r {infinite_image_browser_deps}\n",
        "    !pip install python-dotenv\n",
        "    !pip install -q --upgrade -r {discordia_archivum_deps}\n",
        "\n",
        "def install_dependencies():\n",
        "    requirements_file = os.path.join(repo_dir, \"requirements.txt\")\n",
        "    model_util        = os.path.join(repo_dir, \"library/model_util.py\")\n",
        "    gpu_info          = getoutput('nvidia-smi')\n",
        "    t4_xformers_wheel = \"https://github.com/Linaqruf/colab-xformers/releases/download/0.0.20/xformers-0.0.20+1d635e1.d20230519-cp310-cp310-linux_x86_64.whl\"\n",
        "\n",
        "    !apt install aria2 lz4\n",
        "    !pip install -q --upgrade -r {requirements_file}\n",
        "\n",
        "    if '2.0.1+cu118' in torch.__version__:\n",
        "        if 'T4' in gpu_info:\n",
        "            !pip install -q {t4_xformers_wheel}\n",
        "        else:\n",
        "         !pip3 install -q --upgrade xformers==0.0.20 triton==2.0.0 --force -reinstall\n",
        "         !pip3 install diffusers==0.11.1\n",
        "         !pip3 install transformers scipy ftfy accelerate\n",
        "         !pip3 install bitsandbytes>=0.43.0\n",
        "    else:\n",
        "\n",
        "        from accelerate.utils import write_basic_config\n",
        "\n",
        "        if not os.path.exists(accelerate_config):\n",
        "          write_basic_config(save_location=accelerate_config)\n",
        "\n",
        "def prepare_environment():\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "def main():\n",
        "    os.chdir(root_dir)\n",
        "    clone_repo(repo_url, repo_dir, branch)\n",
        "    os.chdir(repo_dir)\n",
        "    setup_directories()\n",
        "    install_repository()\n",
        "    install_dependencies()\n",
        "    prepare_environment()\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wrYGu-WxFbsq",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68da3b74-602f-4fca-bda8-29790a5c7e66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diffusers model is loaded : stabilityai/stable-diffusion-xl-base-1.0\n",
            "\n",
            "Starting downloading from https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\n",
            "Download finished: /content/vae/sdxl_vae.safetensors\n",
            "\n",
            "Selected model: stabilityai/stable-diffusion-xl-base-1.0\n",
            "Selected VAE: /content/vae/sdxl_vae.safetensors\n"
          ]
        }
      ],
      "source": [
        "# @title ## **1.2. Download SDXL**\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import glob\n",
        "import gdown\n",
        "import requests\n",
        "import subprocess\n",
        "from IPython.utils import capture\n",
        "from urllib.parse import urlparse, unquote\n",
        "from pathlib import Path\n",
        "from huggingface_hub import HfFileSystem\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# @markdown Place your Huggingface token [here](https://huggingface.co/settings/tokens) to download gated models.\n",
        "\n",
        "HUGGINGFACE_TOKEN     = \"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\" #@param {type: \"string\"}\n",
        "LOAD_DIFFUSERS_MODEL  = True #@param {type: \"boolean\"}\n",
        "SDXL_MODEL_URL        = \"stabilityai/stable-diffusion-xl-base-1.0\" # @param [\"gsdf/CounterfeitXL\", \"Linaqruf/animagine-xl\", \"stabilityai/stable-diffusion-xl-base-1.0\", \"PASTE MODEL URL OR GDRIVE PATH HERE\"] {allow-input: true}\n",
        "SDXL_VAE_URL          = \"Original VAE\" # @param [\"None\", \"Original VAE\", \"FP16 VAE\", \"PASTE VAE URL OR GDRIVE PATH HERE\"] {allow-input: true}\n",
        "\n",
        "MODEL_URLS = {\n",
        "    \"gsdf/CounterfeitXL\"        : \"https://huggingface.co/gsdf/CounterfeitXL/resolve/main/CounterfeitXL_%CE%B2.safetensors\",\n",
        "    \"Linaqruf/animagine-xl\"   : \"https://huggingface.co/Linaqruf/animagine-xl/resolve/main/animagine-xl.safetensors\",\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\" : \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors\",\n",
        "}\n",
        "VAE_URLS = {\n",
        "    \"None\"                    : \"\",\n",
        "    \"Original VAE\"           : \"https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\",\n",
        "    \"FP16 VAE\"           : \"https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/sdxl_vae.safetensors\"\n",
        "}\n",
        "\n",
        "SDXL_MODEL_URL = MODEL_URLS.get(SDXL_MODEL_URL, SDXL_MODEL_URL)\n",
        "SDXL_VAE_URL = VAE_URLS.get(SDXL_VAE_URL, SDXL_VAE_URL)\n",
        "\n",
        "def get_filename(url):\n",
        "    if any(url.endswith(ext) for ext in [\".ckpt\", \".safetensors\", \".pt\", \".pth\"]):\n",
        "        return os.path.basename(url)\n",
        "\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    if 'content-disposition' in response.headers:\n",
        "        filename = re.findall('filename=\"?([^\"]+)\"?', response.headers['content-disposition'])[0]\n",
        "    else:\n",
        "        filename = unquote(os.path.basename(urlparse(url).path))\n",
        "\n",
        "    return filename\n",
        "\n",
        "def aria2_download(dir, filename, url):\n",
        "    user_header = f\"Authorization: Bearer {HUGGINGFACE_TOKEN}\"\n",
        "    aria2_args = [\n",
        "        \"aria2c\",\n",
        "        \"--console-log-level=error\",\n",
        "        \"--summary-interval=10\",\n",
        "        f\"--header={user_header}\" if \"huggingface.co\" in url else \"\",\n",
        "        \"--continue=true\",\n",
        "        \"--max-connection-per-server=16\",\n",
        "        \"--min-split-size=1M\",\n",
        "        \"--split=16\",\n",
        "        f\"--dir={dir}\",\n",
        "        f\"--out={filename}\",\n",
        "        url\n",
        "    ]\n",
        "    subprocess.run(aria2_args)\n",
        "\n",
        "def download(url, dst):\n",
        "    print(f\"Starting downloading from {url}\")\n",
        "    filename = get_filename(url)\n",
        "    filepath = os.path.join(dst, filename)\n",
        "\n",
        "    if \"drive.google.com\" in url:\n",
        "        gdown.download(url, filepath, quiet=False)\n",
        "    else:\n",
        "        if \"huggingface.co\" in url and \"/blob/\" in url:\n",
        "            url = url.replace(\"/blob/\", \"/resolve/\")\n",
        "        aria2_download(dst, filename, url)\n",
        "\n",
        "    print(f\"Download finished: {filepath}\")\n",
        "    return filepath\n",
        "\n",
        "def all_folders_present(base_model_url, sub_folders):\n",
        "    fs = HfFileSystem()\n",
        "    existing_folders = set(fs.ls(base_model_url, detail=False))\n",
        "\n",
        "    for folder in sub_folders:\n",
        "        full_folder_path = f\"{base_model_url}/{folder}\"\n",
        "        if full_folder_path not in existing_folders:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def get_total_ram_gb():\n",
        "    with open('/proc/meminfo', 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            if \"MemTotal\" in line:\n",
        "                return int(line.split()[1]) / (1024**2)  # Convert to GB\n",
        "\n",
        "def get_gpu_name():\n",
        "    try:\n",
        "        return subprocess.check_output(\"nvidia-smi --query-gpu=name --format=csv,noheader,nounits\", shell=True).decode('ascii').strip()\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    global model_path, vae_path, LOAD_DIFFUSERS_MODEL\n",
        "\n",
        "    model_path, vae_path = None, None\n",
        "\n",
        "    required_sub_folders = [\n",
        "        'scheduler',\n",
        "        'text_encoder',\n",
        "        'text_encoder_2',\n",
        "        'tokenizer',\n",
        "        'tokenizer_2',\n",
        "        'unet',\n",
        "        'vae',\n",
        "    ]\n",
        "\n",
        "    download_targets = {\n",
        "        \"model\": (SDXL_MODEL_URL, pretrained_model),\n",
        "        \"vae\": (SDXL_VAE_URL, vae_dir),\n",
        "    }\n",
        "\n",
        "    total_ram = get_total_ram_gb()\n",
        "    gpu_name = get_gpu_name()\n",
        "\n",
        "    # Check hardware constraints\n",
        "    if total_ram < 13 and gpu_name in [\"Tesla T4\", \"Tesla V100\"]:\n",
        "        print(\"Attempt to load diffusers model instead due to hardware constraints.\")\n",
        "        if not LOAD_DIFFUSERS_MODEL:\n",
        "            LOAD_DIFFUSERS_MODEL = True\n",
        "\n",
        "    for target, (url, dst) in download_targets.items():\n",
        "        if url and not url.startswith(f\"PASTE {target.upper()} URL OR GDRIVE PATH HERE\"):\n",
        "            if target == \"model\" and LOAD_DIFFUSERS_MODEL:\n",
        "                # Code for checking and handling diffusers model\n",
        "                if 'huggingface.co' in url:\n",
        "                    match = re.search(r'huggingface\\.co/([^/]+)/([^/]+)', SDXL_MODEL_URL)\n",
        "                    if match:\n",
        "                        username = match.group(1)\n",
        "                        model_name = match.group(2)\n",
        "                        url = f\"{username}/{model_name}\"\n",
        "                if all_folders_present(url, required_sub_folders):\n",
        "                    print(f\"Diffusers model is loaded : {url}\")\n",
        "                    model_path = url\n",
        "                else:\n",
        "                    print(\"Repository doesn't exist or no diffusers model detected.\")\n",
        "                    filepath = download(url, dst)  # Continue with the regular download\n",
        "                    model_path = filepath\n",
        "            else:\n",
        "                filepath = download(url, dst)\n",
        "\n",
        "                if target == \"model\":\n",
        "                    model_path = filepath\n",
        "                elif target == \"vae\":\n",
        "                    vae_path = filepath\n",
        "\n",
        "            print()\n",
        "\n",
        "    if model_path:\n",
        "        print(f\"Selected model: {model_path}\")\n",
        "\n",
        "    if vae_path:\n",
        "        print(f\"Selected VAE: {vae_path}\")\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kh7CeDqK4l3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "646c4ad9-4f2e-44f7-cfd0-c8f5d28fd1bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stored 'train_data_dir' (str)\n",
            "Your train data directory : /content/drive/MyDrive/train/js\n"
          ]
        }
      ],
      "source": [
        "# @title ## **1.3. Directory Config**\n",
        "# @markdown Specify the location of your training data in the following cell. A folder with the same name as your input will be created.\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "\n",
        "train_data_dir = \"/content/drive/MyDrive/train/js\"  # @param {'type' : 'string'}\n",
        "%store train_data_dir\n",
        "\n",
        "os.makedirs(train_data_dir, exist_ok=True)\n",
        "print(f\"Your train data directory : {train_data_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-0qKyEgTchp"
      },
      "source": [
        "# **III. Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jz2emq6vWnPu"
      },
      "outputs": [],
      "source": [
        "# @title ## **3.1. Data Cleaning**\n",
        "import os\n",
        "import random\n",
        "import concurrent.futures\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "test = os.listdir(train_data_dir)\n",
        "#@markdown This section removes unsupported media types such as `.mp4`, `.webm`, and `.gif`, as well as any unnecessary files.\n",
        "#@markdown To convert a transparent dataset with an alpha channel (RGBA) to RGB and give it a white background, set the `convert` parameter to `True`.\n",
        "convert = False  # @param {type:\"boolean\"}\n",
        "#@markdown Alternatively, you can give the background a `random_color` instead of white by checking the corresponding option.\n",
        "random_color = False  # @param {type:\"boolean\"}\n",
        "recursive = False\n",
        "\n",
        "batch_size = 32\n",
        "supported_types = [\n",
        "    \".png\",\n",
        "    \".jpg\",\n",
        "    \".jpeg\",\n",
        "    \".webp\",\n",
        "    \".bmp\",\n",
        "    \".caption\",\n",
        "    \".npz\",\n",
        "    \".txt\",\n",
        "    \".json\",\n",
        "]\n",
        "\n",
        "background_colors = [\n",
        "    (255, 255, 255),\n",
        "    (0, 0, 0),\n",
        "    (255, 0, 0),\n",
        "    (0, 255, 0),\n",
        "    (0, 0, 255),\n",
        "    (255, 255, 0),\n",
        "    (255, 0, 255),\n",
        "    (0, 255, 255),\n",
        "]\n",
        "\n",
        "def clean_directory(directory):\n",
        "    for item in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, item)\n",
        "        if os.path.isfile(file_path):\n",
        "            file_ext = os.path.splitext(item)[1]\n",
        "            if file_ext not in supported_types:\n",
        "                print(f\"Deleting file {item} from {directory}\")\n",
        "                os.remove(file_path)\n",
        "        elif os.path.isdir(file_path) and recursive:\n",
        "            clean_directory(file_path)\n",
        "\n",
        "def process_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img_dir, image_name = os.path.split(image_path)\n",
        "\n",
        "    if img.mode in (\"RGBA\", \"LA\"):\n",
        "        if random_color:\n",
        "            background_color = random.choice(background_colors)\n",
        "        else:\n",
        "            background_color = (255, 255, 255)\n",
        "        bg = Image.new(\"RGB\", img.size, background_color)\n",
        "        bg.paste(img, mask=img.split()[-1])\n",
        "\n",
        "        if image_name.endswith(\".webp\"):\n",
        "            bg = bg.convert(\"RGB\")\n",
        "            new_image_path = os.path.join(img_dir, image_name.replace(\".webp\", \".jpg\"))\n",
        "            bg.save(new_image_path, \"JPEG\")\n",
        "            os.remove(image_path)\n",
        "            print(f\" Converted image: {image_name} to {os.path.basename(new_image_path)}\")\n",
        "        else:\n",
        "            bg.save(image_path, \"PNG\")\n",
        "            print(f\" Converted image: {image_name}\")\n",
        "    else:\n",
        "        if image_name.endswith(\".webp\"):\n",
        "            new_image_path = os.path.join(img_dir, image_name.replace(\".webp\", \".jpg\"))\n",
        "            img.save(new_image_path, \"JPEG\")\n",
        "            os.remove(image_path)\n",
        "            print(f\" Converted image: {image_name} to {os.path.basename(new_image_path)}\")\n",
        "        else:\n",
        "            img.save(image_path, \"PNG\")\n",
        "\n",
        "def find_images(directory):\n",
        "    images = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(\".png\") or file.endswith(\".webp\"):\n",
        "                images.append(os.path.join(root, file))\n",
        "    return images\n",
        "\n",
        "clean_directory(train_data_dir)\n",
        "images = find_images(train_data_dir)\n",
        "num_batches = len(images) // batch_size + 1\n",
        "\n",
        "if convert:\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        for i in tqdm(range(num_batches)):\n",
        "            start = i * batch_size\n",
        "            end = start + batch_size\n",
        "            batch = images[start:end]\n",
        "            executor.map(process_image, batch)\n",
        "\n",
        "    print(\"All images have been converted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdISafLeyklg"
      },
      "source": [
        "## **3.2. Data Captioning**\n",
        "\n",
        "- For general images, use BLIP captioning.\n",
        "- For anime and manga-style images, use Waifu Diffusion 1.4 Tagger V2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvPyH-G_Qdha",
        "outputId": "5962d6d4-69db-46a7-bfd6-35a318cb733c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load images from /content/drive/MyDrive/train/js\n",
            "found 58 images.\n",
            "loading BLIP caption: https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
            "Downloading vocab.txt: 100% 232k/232k [00:00<00:00, 8.76MB/s]\n",
            "Downloading tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 316kB/s]\n",
            "Downloading config.json: 100% 570/570 [00:00<00:00, 4.24MB/s]\n",
            "100% 1.66G/1.66G [00:06<00:00, 260MB/s]\n",
            "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
            "BLIP loaded\n",
            "  0% 0/8 [00:00<?, ?it/s]/content/drive/MyDrive/train/js/51274_73264_535.jpg a painting of a waterfall in a mountainous area\n",
            "/content/drive/MyDrive/train/js/GJJS1.jpg a painting of a dragon and a tree\n",
            "/content/drive/MyDrive/train/js/GJJS11.jpeg a painting of a mountain with a waterfall\n",
            "/content/drive/MyDrive/train/js/GJJS12.jpg a painting of a mountain landscape with a river\n",
            "/content/drive/MyDrive/train/js/GJJS13.jpeg a painting of a mountain with a river\n",
            "/content/drive/MyDrive/train/js/GJJS14.jpg a painting of a mountain range with a bird flying over it\n",
            "/content/drive/MyDrive/train/js/GJJS15.jpg a painting of a city with a bridge and a tower\n",
            "/content/drive/MyDrive/train/js/GJJS16.jpg a painting of a mountain with a tree on top\n",
            " 12% 1/8 [00:03<00:27,  4.00s/it]/content/drive/MyDrive/train/js/GJJS17.jpg a painting of a waterfall and a bird in the sky\n",
            "/content/drive/MyDrive/train/js/GJJS18.jpg a painting of a mountain with a village in the distance\n",
            "/content/drive/MyDrive/train/js/GJJS19.jpg a drawing of a mountain with a bridge\n",
            "/content/drive/MyDrive/train/js/GJJS2.jpg a drawing of a mountain scene with a river\n",
            "/content/drive/MyDrive/train/js/GJJS20.php.jpeg a painting of a mountain with a building in the background\n",
            "/content/drive/MyDrive/train/js/GJJS21.jpeg a painting of a mountain with birds flying around\n",
            "/content/drive/MyDrive/train/js/GJJS22.jpeg a painting of a waterfall in a forest\n",
            "/content/drive/MyDrive/train/js/GJJS23.jpeg a painting of a mountain with a lot of trees\n",
            " 25% 2/8 [00:04<00:13,  2.24s/it]/content/drive/MyDrive/train/js/GJJS24.jpeg a painting of a mountain scene with a river\n",
            "/content/drive/MyDrive/train/js/GJJS25.jpeg a painting of a mountain with a village in the middle\n",
            "/content/drive/MyDrive/train/js/GJJS26.jpeg a painting of a mountain scene with a person walking\n",
            "/content/drive/MyDrive/train/js/GJJS27.jpeg a painting of a mountain with a boat in the water\n",
            "/content/drive/MyDrive/train/js/GJJS28.jpeg a painting of a mountain scene with a house and a tree\n",
            "/content/drive/MyDrive/train/js/GJJS29.jpeg a painting of a mountain with a boat in the water\n",
            "/content/drive/MyDrive/train/js/GJJS30.jpeg a painting of mountains and a river with a boat\n",
            "/content/drive/MyDrive/train/js/GJJS31.jpeg a painting of a city with a bridge and a tower\n",
            " 38% 3/8 [00:05<00:08,  1.67s/it]/content/drive/MyDrive/train/js/GJJS32.jpeg a painting of a mountain with a small house on top\n",
            "/content/drive/MyDrive/train/js/GJJS33.jpeg a painting of a mountain range with a lot of trees\n",
            "/content/drive/MyDrive/train/js/GJJS34.jpeg a painting of a mountain landscape with a bridge\n",
            "/content/drive/MyDrive/train/js/GJJS35.jpeg a painting of a waterfall with a person standing in front of it\n",
            "/content/drive/MyDrive/train/js/GJJS36.jpeg a painting of a mountain with a house in the foreground\n",
            "/content/drive/MyDrive/train/js/GJJS37.jpeg a painting of a mountain with a building on top\n",
            "/content/drive/MyDrive/train/js/GJJS38.jpg a painting of a waterfall in a forest\n",
            "/content/drive/MyDrive/train/js/GJJS39.jpg a painting of a mountain landscape with a bridge\n",
            " 50% 4/8 [00:05<00:05,  1.39s/it]/content/drive/MyDrive/train/js/GJJS4.jpg a drawing of a horse and a waterfall\n",
            "/content/drive/MyDrive/train/js/GJJS40.jpg a painting of a mountain with a house in the foreground\n",
            "/content/drive/MyDrive/train/js/GJJS5.jpg a painting of a waterfall in a forest\n",
            "/content/drive/MyDrive/train/js/GJJS7.jpg a painting of a mountain with a lot of trees\n",
            "/content/drive/MyDrive/train/js/GJJS8.jpg a painting of a mountain scene with a rainbow\n",
            "/content/drive/MyDrive/train/js/GJJS9.jpg a painting of a boat in the water near a mountain\n",
            "/content/drive/MyDrive/train/js/R720x0.q80.jpeg a painting of a waterfall in a forest\n",
            "/content/drive/MyDrive/train/js/highjs1.jpeg a painting of a dragon and a tree\n",
            " 62% 5/8 [00:06<00:03,  1.22s/it]/content/drive/MyDrive/train/js/highjs10.jpeg a painting of a mountain with a small house on top\n",
            "/content/drive/MyDrive/train/js/highjs11.jpeg a painting of a waterfall and a bird in a tree\n",
            "/content/drive/MyDrive/train/js/highjs12.jpeg a painting of a mountain with a village in the background\n",
            "/content/drive/MyDrive/train/js/highjs13.jpeg a painting of a mountain with a wave coming out of it\n",
            "/content/drive/MyDrive/train/js/highjs14.jpeg a painting of a mountain with a lot of trees\n",
            "/content/drive/MyDrive/train/js/highjs15.jpeg a painting of a mountain with a lot of trees\n",
            "/content/drive/MyDrive/train/js/highjs16.php.jpeg a painting of a mountain with a building in the background\n",
            "/content/drive/MyDrive/train/js/highjs17.jpeg a painting of a mountain village with a bridge\n",
            " 75% 6/8 [00:06<00:02,  1.10s/it]/content/drive/MyDrive/train/js/highjs18.jpeg a painting of a mountain with a house in the foreground\n",
            "/content/drive/MyDrive/train/js/highjs19.jpeg a painting of a mountain with a building on top\n",
            "/content/drive/MyDrive/train/js/highjs2.jpeg a painting of a mountain with birds flying around\n",
            "/content/drive/MyDrive/train/js/highjs3.jpeg a painting of a mountain with a house on top\n",
            "/content/drive/MyDrive/train/js/highjs4.jpeg a painting of a mountain with a lot of trees\n",
            "/content/drive/MyDrive/train/js/highjs5.jpeg a painting of a mountain scene with a river\n",
            "/content/drive/MyDrive/train/js/highjs6.jpeg a painting of a mountain with a boat in the water\n",
            "/content/drive/MyDrive/train/js/highjs7.jpeg a painting of a mountain with a boat in the water\n",
            "100% 8/8 [00:07<00:00,  1.11it/s]\n",
            "/content/drive/MyDrive/train/js/highjs8.jpeg a painting of mountains and a river with a boat\n",
            "/content/drive/MyDrive/train/js/highjs9.jpeg a painting of a city with a bridge and a tower\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "#@title ### **3.2.1. BLIP Captioning**\n",
        "#@markdown BLIP is a pre-training framework for unified vision-language understanding and generation, which achieves state-of-the-art results on a wide range of vision-language tasks. It can be used as a tool for image captioning, for example, `astronaut riding a horse in space`.\n",
        "import os\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "\n",
        "beam_search = True #@param {type:'boolean'}\n",
        "min_length = 5 #@param {type:\"slider\", min:0, max:100, step:5.0}\n",
        "max_length = 100 #@param {type:\"slider\", min:0, max:100, step:5.0}\n",
        "\n",
        "config = {\n",
        "    \"_train_data_dir\"   : train_data_dir,\n",
        "    \"batch_size\"        : 8,\n",
        "    \"beam_search\"       : beam_search,\n",
        "    \"min_length\"        : min_length,\n",
        "    \"max_length\"        : max_length,\n",
        "    \"debug\"             : True,\n",
        "    \"caption_extension\" : \".caption\",\n",
        "    \"max_data_loader_n_workers\" : 2,\n",
        "    \"recursive\"         : True\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python make_captions.py {args}\"\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rHkSBphHbcE",
        "outputId": "742a09e4-0ef0-44bc-dc62-a8936acfbbfa",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting enhanced text replacement utility.\n",
            "Processed GJJS2.txt\n",
            "Processed GJJS21.txt\n",
            "Processed GJJS27.txt\n",
            "Processed GJJS25.txt\n",
            "Processed GJJS26.txt\n",
            "Processed GJJS22.txt\n",
            "Processed GJJS23.txt\n",
            "Processed GJJS20.php.txt\n",
            "Processed GJJS24.txt\n",
            "Processed GJJS28.txt\n",
            "Processed GJJS29.txt\n",
            "Processed GJJS30.txt\n",
            "Processed GJJS33.txt\n",
            "Processed GJJS32.txt\n",
            "Processed GJJS31.txt\n",
            "Processed GJJS36.txt\n",
            "Processed GJJS34.txt\n",
            "Processed GJJS37.txt\n",
            "Processed GJJS38.txt\n",
            "Processed GJJS4.txt\n",
            "Processed GJJS5.txt\n",
            "Processed GJJS35.txt\n",
            "Processed GJJS40.txt\n",
            "Processed GJJS7.txt\n",
            "Processed GJJS9.txt\n",
            "Processed GJJS8.txt\n",
            "Processed R720x0.q80.txt\n",
            "Processed GJJS39.txt\n",
            "Processed highjs1.txt\n",
            "Processed highjs10.txt\n",
            "Processed highjs11.txt\n",
            "Processed highjs12.txt\n",
            "Processed highjs13.txt\n",
            "Processed highjs14.txt\n",
            "Processed highjs17.txt\n",
            "Processed highjs16.php.txt\n",
            "Processed highjs15.txt\n",
            "Processed highjs18.txt\n",
            "Processed highjs19.txt\n",
            "Processed highjs2.txt\n",
            "Processed highjs3.txt\n",
            "Processed highjs5.txt\n",
            "Processed highjs4.txt\n",
            "Processed highjs6.txt\n",
            "Processed highjs7.txt\n",
            "Processed highjs8.txt\n",
            "Processed highjs9.txt\n",
            "Processed GJJS1.txt\n",
            "Processed GJJS13.txt\n",
            "Processed GJJS11.txt\n",
            "Processed GJJS12.txt\n",
            "Processed GJJS14.txt\n",
            "Processed 51274_73264_535.txt\n",
            "Processed GJJS16.txt\n",
            "Processed GJJS15.txt\n",
            "Processed GJJS19.txt\n",
            "Processed GJJS17.txt\n",
            "Processed GJJS18.txt\n",
            "Total files updated: 58\n"
          ]
        }
      ],
      "source": [
        "# @title ## **Enhanced Batch Text Replacement Tool**\n",
        "import os\n",
        "\n",
        "# Retrieve the stored training data directory\n",
        "%store -r train_data_dir\n",
        "\n",
        "def enhanced_text_replacement(directory_path=train_data_dir, file_name=\"\", original_text=\"Enter original text\", replacement_text=\"Enter replacement text\"):\n",
        "    print(\"Starting enhanced text replacement utility.\")\n",
        "\n",
        "    processed_files = 0\n",
        "    if file_name == \"\":\n",
        "        # Apply changes to all .txt files in the directory\n",
        "        files = [f for f in os.listdir(directory_path) if f.endswith('.txt')]\n",
        "    else:\n",
        "        # Apply changes to the specified file only\n",
        "        files = [file_name] if file_name.endswith('.txt') else [file_name + '.txt']\n",
        "\n",
        "    for filename in files:\n",
        "        file_path = os.path.join(directory_path, filename)\n",
        "        if os.path.isfile(file_path):\n",
        "            try:\n",
        "                with open(file_path, 'r') as file:\n",
        "                    content = file.read()\n",
        "                content = content.replace(original_text, replacement_text)\n",
        "                with open(file_path, 'w') as file:\n",
        "                    file.write(content)\n",
        "                print(f\"Processed {filename}\")\n",
        "                processed_files += 1\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred while processing {file_path}: {e}\")\n",
        "        else:\n",
        "            print(f\"File not found: {filename}\")\n",
        "\n",
        "    print(f\"Total files updated: {processed_files}\")\n",
        "\n",
        "# Colab form fields\n",
        "file_name = \"\" #@param {type:\"string\"}\n",
        "original_text = \"a painting\" #@param {type:\"string\"}\n",
        "replacement_text = \"an inkwash painting by Jeong Seon showing meticulous brush control and ink layering to achieve depth and texture of minimally outlined forms and shapes. His selective use of white space, not merely as voids but as active elements, dynamically structures the composition. Layering techniques and brush velocity variations render detailed terrain and atmospheric effects, distinctively setting his work apart in Korean ink painting.\" #@param {type:\"string\"}\n",
        "\n",
        "# Function call\n",
        "enhanced_text_replacement(file_name=file_name, original_text=original_text, replacement_text=replacement_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-BdXV7rAy2ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9829cfa-2a99-4bbe-ab67-09dbb9d45b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using existing wd14 tagger model\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "found 58 images.\n",
            "  0% 0/8 [00:00<?, ?it/s]\n",
            "/content/drive/MyDrive/train/js/51274_73264_535.jpg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, outdoors, tree, no humans\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS1.jpg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, weapon, tree, no humans, traditional media\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS11.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, no humans, traditional media, scenery, rock, ruins\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS12.jpg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, outdoors, water, tree, no humans, nature, scenery, forest, mountain, chinese text, river\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS13.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, sketch, no humans, traditional media, scenery\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS14.jpg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, comic, outdoors, tree, no humans, traditional media, nature, scenery, mountain\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS15.jpg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, tree, no humans, bird, traditional media, scenery\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS16.jpg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, outdoors, tree, no humans, traditional media, scenery, mountain, house\n",
            " 12% 1/8 [00:04<00:33,  4.83s/it]\n",
            "/content/drive/MyDrive/train/js/GJJS17.jpg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, water, no humans, traditional media, waterfall, fine art parody\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS18.jpg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, comic, outdoors, tree, no humans, traditional media, nature, scenery, forest, mountain, house, landscape\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS19.jpg:\n",
            "  Character tags: \n",
            "  General tags: solo, monochrome, outdoors, no humans\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS2.jpg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, tree, traditional media, backpack, nature, house\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS20.php.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, outdoors, dated, tree, no humans, traditional media, scenery, house\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS21.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, comic, no humans, traditional media, mountain\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS22.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, greyscale, outdoors, water, tree, no humans, nature, scenery, monster, waterfall, shrine\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS23.jpeg:\n",
            "  Character tags: \n",
            "  General tags: outdoors, sky, artist name, cloud, dated, no humans, bird, traditional media, scenery, mountain\n",
            " 25% 2/8 [00:05<00:16,  2.68s/it]\n",
            "/content/drive/MyDrive/train/js/GJJS24.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, outdoors, no humans, scenery\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS25.jpeg:\n",
            "  Character tags: \n",
            "  General tags: tree, no humans, border, nature, scenery, mountain\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS26.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, greyscale, outdoors, water, tree, scenery\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS27.jpeg:\n",
            "  Character tags: \n",
            "  General tags: hat, standing, monochrome, outdoors, tree, border, scenery, mountain, watercraft, boat\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS28.jpeg:\n",
            "  Character tags: \n",
            "  General tags: outdoors, sky, cloud, tree, no humans, traditional media, nature, scenery, mountain, house\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS29.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, comic, outdoors, no humans, traditional media, scenery\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS30.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, comic, outdoors, sky, tree, no humans, traditional media, scenery, mountain\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS31.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, comic, tree, no humans, scenery\n",
            " 38% 3/8 [00:05<00:09,  1.98s/it]\n",
            "/content/drive/MyDrive/train/js/GJJS32.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, outdoors, tree, no humans, traditional media, nature, scenery, mountain, house, fog\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS33.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, comic, no humans, traditional media, nature, scenery\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS34.jpeg:\n",
            "  Character tags: \n",
            "  General tags: outdoors, tree, no humans, traditional media, scenery, rock, mountain, bridge, river\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS35.jpeg:\n",
            "  Character tags: \n",
            "  General tags: outdoors, tree, no humans, nature, scenery, forest, shrine\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS36.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, greyscale, outdoors, tree, no humans, traditional media, house\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS37.jpeg:\n",
            "  Character tags: \n",
            "  General tags: outdoors, sky, tree, no humans, traditional media, scenery, mountain\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS38.jpg:\n",
            "  Character tags: \n",
            "  General tags: outdoors, water, tree, no humans, traditional media, border, nature, scenery, waterfall, statue\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS39.jpg:\n",
            "  Character tags: \n",
            "  General tags: outdoors, water, tree, no humans, traditional media, scenery, rock, mountain, bridge, river, waterfall, silk, spider web\n",
            " 50% 4/8 [00:06<00:06,  1.63s/it]\n",
            "/content/drive/MyDrive/train/js/GJJS4.jpg:\n",
            "  Character tags: \n",
            "  General tags: solo, monochrome, greyscale\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS40.jpg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, greyscale, outdoors, tree, no humans, traditional media, house\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS5.jpg:\n",
            "  Character tags: \n",
            "  General tags: solo, monochrome, water, tree, no humans, nature, waterfall\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS7.jpg:\n",
            "  Character tags: \n",
            "  General tags: no humans, scenery, mountain\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS8.jpg:\n",
            "  Character tags: \n",
            "  General tags: outdoors, water, tree, no humans, traditional media, nature, scenery, river, waterfall\n",
            "\n",
            "/content/drive/MyDrive/train/js/GJJS9.jpg:\n",
            "  Character tags: \n",
            "  General tags: hat, standing, monochrome, outdoors, water, tree, border, scenery, mountain, watercraft, boat\n",
            "\n",
            "/content/drive/MyDrive/train/js/R720x0.q80.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, outdoors, water, tree, no humans, bird, traditional media, border, nature, waterfall\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs1.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, weapon, sword, tree, no humans, traditional media, branch, planted\n",
            " 62% 5/8 [00:07<00:04,  1.41s/it]\n",
            "/content/drive/MyDrive/train/js/highjs10.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, outdoors, tree, no humans, traditional media, nature, scenery, mountain, house, fog\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs11.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, water, no humans, waterfall\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs12.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, comic, outdoors, tree, no humans, traditional media, nature, scenery, forest, mountain, house, landscape\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs13.jpeg:\n",
            "  Character tags: \n",
            "  General tags: solo, monochrome, traditional media, mountain\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs14.jpeg:\n",
            "  Character tags: \n",
            "  General tags: no humans, scenery, mountain\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs15.jpeg:\n",
            "  Character tags: \n",
            "  General tags: comic, outdoors, sky, cloud, tree, no humans, traditional media, nature, scenery, mountain\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs16.php.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, dated, no humans, scenery, mountain, house, cliff\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs17.jpeg:\n",
            "  Character tags: \n",
            "  General tags: outdoors, water, tree, no humans, traditional media, nature, scenery, rock, mountain, house, bridge, river, cliff\n",
            " 75% 6/8 [00:07<00:02,  1.33s/it]\n",
            "/content/drive/MyDrive/train/js/highjs18.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, greyscale, outdoors, tree, no humans, traditional media, house\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs19.jpeg:\n",
            "  Character tags: \n",
            "  General tags: outdoors, sky, artist name, tree, no humans, nature, scenery, mountain, orange sky\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs2.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, no humans, traditional media, mountain, yellow theme\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs3.jpeg:\n",
            "  Character tags: \n",
            "  General tags: outdoors, sky, tree, no humans, traditional media, scenery, mountain, chinese text, house\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs4.jpeg:\n",
            "  Character tags: \n",
            "  General tags: outdoors, sky, artist name, cloud, dated, no humans, bird, traditional media, scenery, mountain\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs5.jpeg:\n",
            "  Character tags: \n",
            "  General tags: outdoors, water, tree, no humans, traditional media, nature, scenery, waterfall\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs6.jpeg:\n",
            "  Character tags: \n",
            "  General tags: hat, standing, monochrome, outdoors, tree, border, scenery, mountain, watercraft, boat\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs7.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, comic, outdoors, no humans, traditional media, scenery\n",
            "100% 8/8 [00:08<00:00,  1.07s/it]\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs8.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, comic, outdoors, sky, tree, no humans, traditional media, scenery, mountain\n",
            "\n",
            "/content/drive/MyDrive/train/js/highjs9.jpeg:\n",
            "  Character tags: \n",
            "  General tags: monochrome, comic, tree, no humans, scenery\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "#@title ### **3.2.2. Waifu Diffusion 1.4 Tagger V2**\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "\n",
        "#@markdown [Waifu Diffusion 1.4 Tagger V2](https://huggingface.co/spaces/SmilingWolf/wd-v1-4-tags) is a Danbooru-styled image classification model developed by SmilingWolf. It can also be useful for general image tagging, for example, `1girl, solo, looking_at_viewer, short_hair, bangs, simple_background`.\n",
        "model = \"SmilingWolf/wd-v1-4-moat-tagger-v2\" #@param [\"SmilingWolf/wd-v1-4-moat-tagger-v2\", \"SmilingWolf/wd-v1-4-convnextv2-tagger-v2\", \"SmilingWolf/wd-v1-4-swinv2-tagger-v2\", \"SmilingWolf/wd-v1-4-convnext-tagger-v2\", \"SmilingWolf/wd-v1-4-vit-tagger-v2\"]\n",
        "#@markdown Separate `undesired_tags` with comma `(,)` if you want to remove multiple tags, e.g. `1girl,solo,smile`.\n",
        "undesired_tags = \"chiense text,acrylic,oil painting,chinese,japanese,traditional,architecture,building,east asian architecture,torii\" #@param {type:'string'}\n",
        "#@markdown Adjust `general_threshold` for pruning tags (less tags, less flexible). `character_threshold` is useful if you want to train with character tags, e.g. `hakurei reimu`.\n",
        "general_threshold = 0.35 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "character_threshold = 0.85 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "\n",
        "config = {\n",
        "    \"_train_data_dir\"           : train_data_dir,\n",
        "    \"batch_size\"                : 8,\n",
        "    \"repo_id\"                   : model,\n",
        "    \"recursive\"                 : True,\n",
        "    \"remove_underscore\"         : True,\n",
        "    \"general_threshold\"         : general_threshold,\n",
        "    \"character_threshold\"       : character_threshold,\n",
        "    \"caption_extension\"         : \".txt\",\n",
        "    \"max_data_loader_n_workers\" : 2,\n",
        "    \"debug\"                     : True,\n",
        "    \"undesired_tags\"            : undesired_tags\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python tag_images_by_wd14_tagger.py {args}\"\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k10WYGu6Zt1q"
      },
      "source": [
        "# **Adding Text in front**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axsIca0Nnxhr",
        "outputId": "a4b2eb3c-5064-4b07-818f-ef00c8584498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting text prepend utility.\n",
            "Processed GJJS2.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS21.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS27.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS25.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS26.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS22.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS23.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS20.php.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS24.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS28.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS29.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS30.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS33.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS32.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS31.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS36.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS34.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS37.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS38.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS4.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS5.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS35.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS40.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS7.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS9.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS8.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed R720x0.q80.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS39.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs1.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs10.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs11.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs12.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs13.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs14.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs17.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs16.php.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs15.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs18.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs19.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs2.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs3.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs5.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs4.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs6.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs7.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs8.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed highjs9.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS1.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS13.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS11.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS12.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS14.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed 51274_73264_535.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS16.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS15.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS19.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS17.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "Processed GJJS18.txt\n",
            "Prepended text: Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\n",
            "All files have been processed. Total files updated: 58\n"
          ]
        }
      ],
      "source": [
        "#@title ### **Prepend Text to Files Function**\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "\n",
        "# Function to prepend text to a file\n",
        "def prepend_text_to_files(directory_path=\"/content/drive/MyDrive/train/renoir\", text_to_prepend=\"Enter text to prepend\"):\n",
        "    print(\"Starting text prepend utility.\")\n",
        "\n",
        "\n",
        "    directory_path = train_data_dir\n",
        "    #@markdown Enter the text to prepend:\n",
        "    text_to_prepend = \"Jeong Seon, true-view landscapes, Korean painting, brush control, ink layering, minimalistic color palette, selective use of white space, expressive brushwork, natural vistas, artistic innovation, traditional Korean art, spatial depth, locality-specific depictions, mountainous terrain, subtle ink gradients, atmospheric perspective, rhythmic composition, environmental immersion, East Asian aesthetics, minimal depiction, brush velocity variations, texture enhancement, bold brushworks, vivid depiction, strong outline of shapes and forms,  compositional structuring\" #@param {type:\"string\"}\n",
        "\n",
        "    processed_files = 0\n",
        "    # Iterate over each file in the directory\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.endswith('.txt'):\n",
        "            file_path = os.path.join(directory_path, filename)\n",
        "            try:\n",
        "                with open(file_path, 'r') as file:\n",
        "                    original_content = file.read()\n",
        "\n",
        "                new_content = text_to_prepend + original_content\n",
        "                with open(file_path, 'w') as file:\n",
        "                    file.write(new_content)\n",
        "\n",
        "                print(f\"Processed {filename}\")\n",
        "                print(f\"Prepended text: {text_to_prepend}\")\n",
        "                processed_files += 1\n",
        "            except IOError as e:\n",
        "                print(f\"An error occurred while processing {file_path}: {e}\")\n",
        "\n",
        "    print(f\"All files have been processed. Total files updated: {processed_files}\")\n",
        "\n",
        "# Run the function with default arguments\n",
        "prepend_text_to_files()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_mLVURhM9PFE"
      },
      "outputs": [],
      "source": [
        "# @title ### **3.2.3. Custom Caption/Tag**\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# @markdown Add or remove custom tags here.\n",
        "extension   = \".txt\"  # @param [\".txt\", \".caption\"]\n",
        "custom_tag  = \"stylishsolo\"  # @param {type:\"string\"}\n",
        "# @markdown Use `sub_folder` option to specify a subfolder for multi-concept training.\n",
        "# @markdown > Specify `--all` to process all subfolders/`recursive`\n",
        "sub_folder  = \"\" #@param {type: \"string\"}\n",
        "# @markdown Enable this to append custom tags at the end of lines.\n",
        "append      = True  # @param {type:\"boolean\"}\n",
        "# @markdown Enable this if you want to remove captions/tags instead.\n",
        "remove_tag  = False  # @param {type:\"boolean\"}\n",
        "recursive   = False\n",
        "\n",
        "if sub_folder == \"\":\n",
        "    image_dir = train_data_dir\n",
        "elif sub_folder == \"--all\":\n",
        "    image_dir = train_data_dir\n",
        "    recursive = True\n",
        "elif sub_folder.startswith(\"/content\"):\n",
        "    image_dir = sub_folder\n",
        "else:\n",
        "    image_dir = os.path.join(train_data_dir, sub_folder)\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "def process_tags(filename, custom_tag, append, remove_tag):\n",
        "    contents = read_file(filename)\n",
        "    tags = [tag.strip() for tag in contents.split(',')]\n",
        "    custom_tags = [tag.strip() for tag in custom_tag.split(',')]\n",
        "\n",
        "    for custom_tag in custom_tags:\n",
        "        custom_tag = custom_tag.replace(\"_\", \" \")\n",
        "        if remove_tag:\n",
        "            while custom_tag in tags:\n",
        "                tags.remove(custom_tag)\n",
        "        else:\n",
        "            if custom_tag not in tags:\n",
        "                if append:\n",
        "                    tags.append(custom_tag)\n",
        "                else:\n",
        "                    tags.insert(0, custom_tag)\n",
        "\n",
        "    contents = ', '.join(tags)\n",
        "    write_file(filename, contents)\n",
        "\n",
        "def process_directory(image_dir, tag, append, remove_tag, recursive):\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "\n",
        "        if os.path.isdir(file_path) and recursive:\n",
        "            process_directory(file_path, tag, append, remove_tag, recursive)\n",
        "        elif filename.endswith(extension):\n",
        "            process_tags(file_path, tag, append, remove_tag)\n",
        "\n",
        "tag = custom_tag\n",
        "\n",
        "if not any(\n",
        "    [filename.endswith(extension) for filename in os.listdir(image_dir)]\n",
        "):\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if filename.endswith((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")):\n",
        "            open(\n",
        "                os.path.join(image_dir, filename.split(\".\")[0] + extension),\n",
        "                \"w\",\n",
        "            ).close()\n",
        "\n",
        "if custom_tag:\n",
        "    process_directory(image_dir, tag, append, remove_tag, recursive)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAZVkLuaRJ9e"
      },
      "source": [
        "# **IV. Training**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhgatqF3leHJ",
        "outputId": "29692606-b386-4de3-ee17-11769fd741cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 58 images.\n",
            "Creating a new metadata file\n",
            "Merging tags and captions into metadata json.\n",
            "100% 58/58 [00:00<00:00, 71.27it/s]\n",
            "All 58 images have captions\n",
            "All 58 images have tags\n",
            "Cleaning captions and tags.\n",
            "100% 58/58 [00:00<00:00, 5437.04it/s]\n",
            "Writing metadata: /content/LoRA/meta_clean.json\n",
            "Done!\n",
            "found 58 images.\n",
            "loading existing metadata: /content/LoRA/meta_clean.json\n",
            "load VAE: /content/vae/sdxl_vae.safetensors\n",
            "100% 58/58 [00:09<00:00,  6.27it/s]\n",
            "bucket 0 (384, 1024): 1\n",
            "bucket 1 (448, 1024): 3\n",
            "bucket 2 (512, 1024): 1\n",
            "bucket 3 (576, 1024): 5\n",
            "bucket 4 (640, 1024): 1\n",
            "bucket 5 (704, 1024): 1\n",
            "bucket 6 (768, 1024): 24\n",
            "bucket 7 (832, 1024): 4\n",
            "bucket 8 (896, 1024): 1\n",
            "bucket 9 (1024, 576): 6\n",
            "bucket 10 (1024, 640): 1\n",
            "bucket 11 (1024, 704): 4\n",
            "bucket 12 (1024, 960): 2\n",
            "bucket 13 (1024, 1024): 4\n",
            "mean ar error: 0.023013257324512912\n",
            "writing metadata: /content/LoRA/meta_lat.json\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "# @title ## **3.4. Bucketing and Latents Caching**\n",
        "%store -r\n",
        "\n",
        "# @markdown This code will create buckets based on the `bucket_resolution` provided for multi-aspect ratio training, and then convert all images within the `train_data_dir` to latents.\n",
        "bucketing_json    = os.path.join(training_dir, \"meta_lat.json\")\n",
        "metadata_json     = os.path.join(training_dir, \"meta_clean.json\")\n",
        "bucket_resolution = 1024  # @param {type:\"slider\", min:512, max:1024, step:128}\n",
        "mixed_precision   = \"no\"  # @param [\"no\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "skip_existing     = False  # @param{type:\"boolean\"}\n",
        "flip_aug          = False  # @param{type:\"boolean\"}\n",
        "# @markdown Use `clean_caption` option to clean such as duplicate tags, `women` to `girl`, etc\n",
        "clean_caption     = True #@param {type:\"boolean\"}\n",
        "#@markdown Use the `recursive` option to process subfolders as well\n",
        "recursive         = True #@param {type:\"boolean\"}\n",
        "\n",
        "metadata_config = {\n",
        "    \"_train_data_dir\": train_data_dir,\n",
        "    \"_out_json\": metadata_json,\n",
        "    \"recursive\": recursive,\n",
        "    \"full_path\": recursive,\n",
        "    \"clean_caption\": clean_caption\n",
        "}\n",
        "\n",
        "bucketing_config = {\n",
        "    \"_train_data_dir\": train_data_dir,\n",
        "    \"_in_json\": metadata_json,\n",
        "    \"_out_json\": bucketing_json,\n",
        "    \"_model_name_or_path\": vae_path if vae_path else model_path,\n",
        "    \"recursive\": recursive,\n",
        "    \"full_path\": recursive,\n",
        "    \"flip_aug\": flip_aug,\n",
        "    \"skip_existing\": skip_existing,\n",
        "    \"batch_size\": 4,\n",
        "    \"max_data_loader_n_workers\": 2,\n",
        "    \"max_resolution\": f\"{bucket_resolution}, {bucket_resolution}\",\n",
        "    \"mixed_precision\": mixed_precision,\n",
        "}\n",
        "\n",
        "def generate_args(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "    return args.strip()\n",
        "\n",
        "merge_metadata_args = generate_args(metadata_config)\n",
        "prepare_buckets_args = generate_args(bucketing_config)\n",
        "\n",
        "merge_metadata_command = f\"python merge_all_to_metadata.py {merge_metadata_args}\"\n",
        "prepare_buckets_command = f\"python prepare_buckets_latents.py {prepare_buckets_args}\"\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "!{merge_metadata_command}\n",
        "time.sleep(1)\n",
        "!{prepare_buckets_command}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJgLfRtlHSjw",
        "outputId": "edc75b6d-8f1d-487a-ac55-740082d54cc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[additional_network_arguments]\n",
            "no_metadata = false\n",
            "network_module = \"networks.lora\"\n",
            "network_dim = 16\n",
            "network_alpha = 4\n",
            "network_args = [ \"conv_dim=8\", \"conv_alpha=1\",]\n",
            "network_train_unet_only = true\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import toml\n",
        "\n",
        "# @title ## **4.1. LoRa: Low-Rank Adaptation Config**\n",
        "# @markdown Kohya's `LoRA` renamed to `LoRA-LierLa` and Kohya's `LoCon` renamed to `LoRA-C3Lier`, read [official announcement](https://github.com/kohya-ss/sd-scripts/blob/849bc24d205a35fbe1b2a4063edd7172533c1c01/README.md#naming-of-lora).\n",
        "network_category = \"LoRA_C3Lier\"  # @param [\"LoRA_LierLa\", \"LoRA_C3Lier\", \"DyLoRA_LierLa\", \"DyLoRA_C3Lier\", \"LoCon\", \"LoHa\", \"IA3\", \"LoKR\", \"DyLoRA_Lycoris\"]\n",
        "\n",
        "# @markdown | network_category | network_dim | network_alpha | conv_dim | conv_alpha | unit |\n",
        "# @markdown | :---: | :---: | :---: | :---: | :---: | :---: |\n",
        "# @markdown | LoRA-LierLa | 32 | 1 | - | - | - |\n",
        "# @markdown | LoCon/LoRA-C3Lier | 16 | 8 | 8 | 1 | - |\n",
        "# @markdown | LoHa | 8 | 4 | 4 | 1 | - |\n",
        "# @markdown | Other Category | ? | ? | ? | ? | - |\n",
        "\n",
        "# @markdown Specify `network_args` to add `optional` training args, like for specifying each 25 block weight, read [this](https://github.com/kohya-ss/sd-scripts/blob/main/train_network_README-ja.md#%E9%9A%8E%E5%B1%A4%E5%88%A5%E5%AD%A6%E7%BF%92%E7%8E%87)\n",
        "network_args    = \"\"  # @param {'type':'string'}\n",
        "\n",
        "# @markdown ### **Linear Layer Config**\n",
        "# @markdown Used by all `network_category`. When in doubt, set `network_dim = network_alpha`\n",
        "network_dim     = 16  # @param {'type':'number'}\n",
        "network_alpha   = 4  # @param {'type':'number'}\n",
        "\n",
        "# @markdown ### **Convolutional Layer Config**\n",
        "# @markdown Only required if `network_category` is not `LoRA_LierLa`, as it involves training convolutional layers in addition to linear layers.\n",
        "conv_dim        = 8  # @param {'type':'number'}\n",
        "conv_alpha      = 1  # @param {'type':'number'}\n",
        "\n",
        "# @markdown ### **DyLoRA Config**\n",
        "# @markdown Only required if `network_category` is `DyLoRA_LierLa` and `DyLoRA_C3Lier`\n",
        "unit = 3  # @param {'type':'number'}\n",
        "\n",
        "if isinstance(network_args, str):\n",
        "    network_args = network_args.strip()\n",
        "    if network_args.startswith('[') and network_args.endswith(']'):\n",
        "        try:\n",
        "            network_args = ast.literal_eval(network_args)\n",
        "        except (SyntaxError, ValueError) as e:\n",
        "            print(f\"Error parsing network_args: {e}\\n\")\n",
        "            network_args = []\n",
        "    elif len(network_args) > 0:\n",
        "        print(f\"WARNING! '{network_args}' is not a valid list! Put args like this: [\\\"args=1\\\", \\\"args=2\\\"]\\n\")\n",
        "        network_args = []\n",
        "    else:\n",
        "        network_args = []\n",
        "else:\n",
        "    network_args = []\n",
        "\n",
        "network_config = {\n",
        "    \"LoRA_LierLa\": {\n",
        "        \"module\": \"networks.lora\",\n",
        "        \"args\"  : []\n",
        "    },\n",
        "    \"LoRA_C3Lier\": {\n",
        "        \"module\": \"networks.lora\",\n",
        "        \"args\"  : [\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"DyLoRA_LierLa\": {\n",
        "        \"module\": \"networks.dylora\",\n",
        "        \"args\"  : [\n",
        "            f\"unit={unit}\"\n",
        "        ]\n",
        "    },\n",
        "    \"DyLoRA_C3Lier\": {\n",
        "        \"module\": \"networks.dylora\",\n",
        "        \"args\"  : [\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\",\n",
        "            f\"unit={unit}\"\n",
        "        ]\n",
        "    },\n",
        "    \"LoCon\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=locon\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"LoHa\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=loha\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"IA3\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=ia3\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"LoKR\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=lokr\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"DyLoRA_Lycoris\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=dylora\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "network_module = network_config[network_category][\"module\"]\n",
        "network_args.extend(network_config[network_category][\"args\"])\n",
        "\n",
        "lora_config = {\n",
        "    \"additional_network_arguments\": {\n",
        "        \"no_metadata\"                     : False,\n",
        "        \"network_module\"                  : network_module,\n",
        "        \"network_dim\"                     : network_dim,\n",
        "        \"network_alpha\"                   : network_alpha,\n",
        "        \"network_args\"                    : network_args,\n",
        "        \"network_train_unet_only\"         : True,\n",
        "        \"training_comment\"                : None,\n",
        "    },\n",
        "}\n",
        "\n",
        "print(toml.dumps(lora_config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNlw3u8arwir",
        "outputId": "f4ed3a19-2cfa-4068-af10-3a0f54532460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[optimizer_arguments]\n",
            "optimizer_type = \"AdaFactor\"\n",
            "learning_rate = 0\n",
            "max_grad_norm = 0\n",
            "optimizer_args = []\n",
            "lr_scheduler = \"adafactor\"\n",
            "lr_warmup_steps = 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import toml\n",
        "import ast\n",
        "\n",
        "# @title ## **4.2. Optimizer Config**\n",
        "# @markdown Use `Adafactor` optimizer. `RMSprop 8bit` or `Adagrad 8bit` may work. `AdamW 8bit` doesn't seem to work.\n",
        "optimizer_type = \"AdaFactor\"  # @param [\"AdamW\", \"AdamW8bit\", \"Lion8bit\", \"Lion\", \"SGDNesterov\", \"SGDNesterov8bit\", \"DAdaptation(DAdaptAdamPreprint)\", \"DAdaptAdaGrad\", \"DAdaptAdam\", \"DAdaptAdan\", \"DAdaptAdanIP\", \"DAdaptLion\", \"DAdaptSGD\", \"AdaFactor\"]\n",
        "# @markdown Specify `optimizer_args` to add `additional` args for optimizer, e.g: `[\"weight_decay=0.6\"]`\n",
        "optimizer_args = \"\"  # @param {'type':'string'}\n",
        "# @markdown ### **Learning Rate Config**\n",
        "# @markdown Different `optimizer_type` and `network_category` for some condition requires different learning rate. It's recommended to set `text_encoder_lr = 1/2 * unet_lr`\n",
        "learning_rate = 0  # @param {'type':'number'}\n",
        "# @markdown ### **LR Scheduler Config**\n",
        "# @markdown `lr_scheduler` provides several methods to adjust the learning rate based on the number of epochs.\n",
        "lr_scheduler = \"adafactor\"  # @param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\", \"adafactor\"] {allow-input: false}\n",
        "lr_warmup_steps = 0  # @param {'type':'number'}\n",
        "# @markdown Specify `lr_scheduler_num` with `num_cycles` value for `cosine_with_restarts` or `power` value for `polynomial`\n",
        "lr_scheduler_num = 0  # @param {'type':'number'}\n",
        "\n",
        "if isinstance(optimizer_args, str):\n",
        "    optimizer_args = optimizer_args.strip()\n",
        "    if optimizer_args.startswith('[') and optimizer_args.endswith(']'):\n",
        "        try:\n",
        "            optimizer_args = ast.literal_eval(optimizer_args)\n",
        "        except (SyntaxError, ValueError) as e:\n",
        "            print(f\"Error parsing optimizer_args: {e}\\n\")\n",
        "            optimizer_args = []\n",
        "    elif len(optimizer_args) > 0:\n",
        "        print(f\"WARNING! '{optimizer_args}' is not a valid list! Put args like this: [\\\"args=1\\\", \\\"args=2\\\"]\\n\")\n",
        "        optimizer_args = []\n",
        "    else:\n",
        "        optimizer_args = []\n",
        "else:\n",
        "    optimizer_args = []\n",
        "\n",
        "optimizer_config = {\n",
        "    \"optimizer_arguments\": {\n",
        "        \"optimizer_type\"          : optimizer_type,\n",
        "        \"learning_rate\"           : learning_rate,\n",
        "        \"max_grad_norm\"           : 0,\n",
        "        \"optimizer_args\"          : optimizer_args,\n",
        "        \"lr_scheduler\"            : lr_scheduler,\n",
        "        \"lr_warmup_steps\"         : lr_warmup_steps,\n",
        "        \"lr_scheduler_num_cycles\" : lr_scheduler_num if lr_scheduler == \"cosine_with_restarts\" else None,\n",
        "        \"lr_scheduler_power\"      : lr_scheduler_num if lr_scheduler == \"polynomial\" else None,\n",
        "        \"lr_scheduler_type\"       : None,\n",
        "        \"lr_scheduler_args\"       : None,\n",
        "    },\n",
        "}\n",
        "\n",
        "print(toml.dumps(optimizer_config))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOxNM0x7dvfO",
        "outputId": "f6e57f06-46ec-4ac3-f92f-dc087e60d61b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[advanced_training_config]\n",
            "resume = \"/content/drive/MyDrive/kohya-trainer/output/JJS_re/JJS_re-000010-state\"\n",
            "save_state = true\n",
            "save_last_n_epochs_state = true\n",
            "multires_noise_iterations = 7\n",
            "multires_noise_discount = 0.9\n",
            "min_snr_gamma = 2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title ## **4.3. Advanced Training Config** (Optional)\n",
        "import toml\n",
        "\n",
        "\n",
        "# @markdown ### **Optimizer State Config**\n",
        "save_optimizer_state      = True #@param {type:\"boolean\"}\n",
        "load_optimizer_state      = \"/content/drive/MyDrive/kohya-trainer/output/JJS_re/JJS_re-000010-state\" #@param {type:\"string\"}\n",
        "# @markdown ### **Noise Control**\n",
        "noise_control_type        = \"multires_noise\" #@param [\"none\", \"noise_offset\", \"multires_noise\"]\n",
        "# @markdown #### **a. Noise Offset**\n",
        "# @markdown Control and easily generating darker or light images by offset the noise when fine-tuning the model. Recommended value: `0.1`. Read [Diffusion With Offset Noise](https://www.crosslabs.org//blog/diffusion-with-offset-noise)\n",
        "noise_offset_num          = 0.158  # @param {type:\"number\"}\n",
        "# @markdown **[Experimental]**\n",
        "# @markdown Automatically adjusts the noise offset based on the absolute mean values of each channel in the latents when used with `--noise_offset`. Specify a value around 1/10 to the same magnitude as the `--noise_offset` for best results. Set `0` to disable.\n",
        "adaptive_noise_scale      = 0.0158 # @param {type:\"number\"}\n",
        "# @markdown #### **b. Multires Noise**\n",
        "# @markdown enable multires noise with this number of iterations (if enabled, around 6-10 is recommended)\n",
        "multires_noise_iterations = 7 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "multires_noise_discount = 0.9 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n",
        "# @markdown ### **Caption Dropout**\n",
        "caption_dropout_rate = None  # @param {type:\"number\"}\n",
        "caption_tag_dropout_rate = None  # @param {type:\"number\"}\n",
        "caption_dropout_every_n_epochs = None  # @param {type:\"number\"}\n",
        "# @markdown ### **Custom Train Function**\n",
        "# @markdown Gamma for reducing the weight of high-loss timesteps. Lower numbers have a stronger effect. The paper recommends `5`. Read the paper [here](https://arxiv.org/abs/2303.09556).\n",
        "min_snr_gamma             = 2 #@param {type:\"number\"}\n",
        "\n",
        "advanced_training_config = {\n",
        "    \"advanced_training_config\": {\n",
        "        \"resume\"                        : load_optimizer_state,\n",
        "        \"save_state\"                    : save_optimizer_state,\n",
        "        \"save_last_n_epochs_state\"      : save_optimizer_state,\n",
        "        \"noise_offset\"                  : noise_offset_num if noise_control_type == \"noise_offset\" else None,\n",
        "        \"adaptive_noise_scale\"          : adaptive_noise_scale if adaptive_noise_scale and noise_control_type == \"noise_offset\" else None,\n",
        "        \"multires_noise_iterations\"     : multires_noise_iterations if noise_control_type ==\"multires_noise\" else None,\n",
        "        \"multires_noise_discount\"       : multires_noise_discount if noise_control_type ==\"multires_noise\" else None,\n",
        "        \"caption_dropout_rate\"          : caption_dropout_rate,\n",
        "        \"caption_tag_dropout_rate\"      : caption_tag_dropout_rate,\n",
        "        \"caption_dropout_every_n_epochs\": caption_dropout_every_n_epochs,\n",
        "        \"min_snr_gamma\"                 : min_snr_gamma if not min_snr_gamma == -1 else None,\n",
        "    }\n",
        "}\n",
        "\n",
        "print(toml.dumps(advanced_training_config))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3TWaOuW0PSu"
      },
      "source": [
        "### *LEARNING RATE FINDER:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z4w3lfFKLjr",
        "outputId": "ee4dbfb1-6a4b-4f04-c204-6dd03c5f2853",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[sdxl_arguments]\n",
            "cache_text_encoder_outputs = true\n",
            "no_half_vae = true\n",
            "min_timestep = 0\n",
            "max_timestep = 1000\n",
            "shuffle_caption = false\n",
            "lowram = false\n",
            "\n",
            "[model_arguments]\n",
            "pretrained_model_name_or_path = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
            "vae = \"/content/vae/sdxl_vae.safetensors\"\n",
            "\n",
            "[dataset_arguments]\n",
            "debug_dataset = false\n",
            "in_json = \"/content/LoRA/meta_lat.json\"\n",
            "train_data_dir = \"/content/drive/MyDrive/train/js\"\n",
            "dataset_repeats = 2\n",
            "keep_tokens = 0\n",
            "resolution = \"1024,1024\"\n",
            "color_aug = false\n",
            "token_warmup_min = 1\n",
            "token_warmup_step = 0\n",
            "\n",
            "[training_arguments]\n",
            "output_dir = \"/content/drive/MyDrive/kohya-trainer/output/JJS_rerere\"\n",
            "output_name = \"JJS_rerere\"\n",
            "save_precision = \"float\"\n",
            "save_every_n_epochs = 2\n",
            "train_batch_size = 4\n",
            "max_token_length = 225\n",
            "mem_eff_attn = false\n",
            "sdpa = false\n",
            "xformers = true\n",
            "max_train_epochs = 12\n",
            "max_data_loader_n_workers = 8\n",
            "persistent_data_loader_workers = true\n",
            "gradient_checkpointing = true\n",
            "mixed_precision = \"no\"\n",
            "\n",
            "[logging_arguments]\n",
            "log_with = \"wandb\"\n",
            "log_tracker_name = \"JJS_rerere\"\n",
            "logging_dir = \"/content/LoRA/logs\"\n",
            "\n",
            "[sample_prompt_arguments]\n",
            "sample_every_n_epochs = 2\n",
            "sample_sampler = \"heun\"\n",
            "\n",
            "[saving_arguments]\n",
            "save_model_as = \"safetensors\"\n",
            "\n",
            "[optimizer_arguments]\n",
            "optimizer_type = \"AdaFactor\"\n",
            "learning_rate = 0\n",
            "max_grad_norm = 0\n",
            "optimizer_args = []\n",
            "lr_scheduler = \"adafactor\"\n",
            "lr_warmup_steps = 0\n",
            "\n",
            "[additional_network_arguments]\n",
            "no_metadata = false\n",
            "network_module = \"networks.lora\"\n",
            "network_dim = 16\n",
            "network_alpha = 4\n",
            "network_args = [ \"conv_dim=8\", \"conv_alpha=1\",]\n",
            "network_train_unet_only = true\n",
            "\n",
            "[advanced_training_config]\n",
            "resume = \"/content/drive/MyDrive/kohya-trainer/output/JJS_re/JJS_re-000010-state\"\n",
            "save_state = true\n",
            "save_last_n_epochs_state = true\n",
            "multires_noise_iterations = 7\n",
            "multires_noise_discount = 0.9\n",
            "min_snr_gamma = 2\n",
            "\n",
            "[prompt]\n",
            "negative_prompt = \"east asian architecture, arcitecture, perspective, text, seal, chinese, jpanese\"\n",
            "width = 1024\n",
            "height = 1024\n",
            "scale = 12\n",
            "sample_steps = 28\n",
            "[[prompt.subset]]\n",
            "prompt = \"a painting by jeongseon, korean ink wash painting, cityscape of Rio,\"\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title ## **4.4. Training Config**\n",
        "import toml\n",
        "import os\n",
        "from subprocess import getoutput\n",
        "\n",
        "%store -r\n",
        "\n",
        "# @markdown ### **Project Config**\n",
        "project_name                = \"JJS_rerere\"  # @param {type:\"string\"}\n",
        "# @markdown Get your `wandb_api_key` [here](https://wandb.ai/settings) to logs with wandb.\n",
        "wandb_api_key               = \"855a9e4f2b1aa8b2e2e27e9c1c1373071fb23c42\" # @param {type:\"string\"}\n",
        "in_json                     = \"/content/LoRA/meta_lat.json\"  # @param {type:\"string\"}\n",
        "# @markdown ### **SDXL Config**\n",
        "gradient_checkpointing      = True  # @param {type:\"boolean\"}\n",
        "no_half_vae                 = True  # @param {type:\"boolean\"}\n",
        "#@markdown Recommended parameter for SDXL training but if you enable it, `shuffle_caption` won't work\n",
        "cache_text_encoder_outputs  = True  # @param {type:\"boolean\"}\n",
        "#@markdown These options can be used to train U-Net with different timesteps. The default values are 0 and 1000.\n",
        "min_timestep                = 0 # @param {type:\"number\"}\n",
        "max_timestep                = 1000 # @param {type:\"number\"}\n",
        "# @markdown ### **Dataset Config**\n",
        "num_repeats                 = 2  # @param {type:\"number\"}\n",
        "resolution                  = 1024  # @param {type:\"slider\", min:512, max:1024, step:128}\n",
        "keep_tokens                 = 0  # @param {type:\"number\"}\n",
        "# @markdown ### **General Config**\n",
        "num_epochs                  = 12  # @param {type:\"number\"}\n",
        "train_batch_size            = 4  # @param {type:\"number\"}\n",
        "mixed_precision             = \"no\"  # @param [\"no\",\"fp16\",\"bf16\"] {allow-input: false}\n",
        "seed                        = -1  # @param {type:\"number\"}\n",
        "optimization                = \"xformers\" # @param [\"xformers\", \"scaled dot-product attention\"]\n",
        "# @markdown ### **Save Output Config**\n",
        "save_precision              = \"float\"  # @param [\"float\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "save_every_n_epochs         = 2  # @param {type:\"number\"}\n",
        "# @markdown ### **Sample Prompt Config**\n",
        "enable_sample               = True  # @param {type:\"boolean\"}\n",
        "sampler                     = \"heun\"  # @param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
        "positive_prompt             = \"\"\n",
        "negative_prompt             = \"\"\n",
        "quality_prompt              = \"Stable Diffusion XL\"  # @param [\"None\", \"Waifu Diffusion 1.5\", \"NovelAI\", \"AbyssOrangeMix\", \"Stable Diffusion XL\"] {allow-input: false}\n",
        "if quality_prompt          == \"NovelAI\":\n",
        "    positive_prompt         = \"masterpiece, best quality, \"\n",
        "    negative_prompt         = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, \"\n",
        "if quality_prompt          == \"AbyssOrangeMix\":\n",
        "    positive_prompt         = \"masterpiece, best quality, \"\n",
        "    negative_prompt         = \"(worst quality, low quality:1.4), \"\n",
        "if quality_prompt          == \"Stable Diffusion XL\":\n",
        "    negative_prompt         = \"3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\"\n",
        "custom_prompt               = \"a painting by jeongseon, korean ink wash painting, cityscape of Rio,\" # @param {type:\"string\"}\n",
        "# @markdown Specify `prompt_from_caption` if you want to use caption as prompt instead. Will be chosen randomly.\n",
        "prompt_from_caption         = \"none\"  # @param [\"none\", \".txt\", \".caption\"]\n",
        "if prompt_from_caption     != \"none\":\n",
        "    custom_prompt           = \"\"\n",
        "num_prompt                  = 10  # @param {type:\"number\"}\n",
        "negative_prompt = \"east asian architecture, arcitecture, perspective, text, seal, chinese, jpanese\" # @param {type:\"string\"}\n",
        "logging_dir                 = os.path.join(training_dir, \"logs\")\n",
        "lowram                      = int(next(line.split()[1] for line in open('/proc/meminfo') if \"MemTotal\" in line)) / (1024**2) < 15\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "\n",
        "prompt_config = {\n",
        "    \"prompt\": {\n",
        "        \"negative_prompt\" : negative_prompt,\n",
        "        \"width\"           : resolution,\n",
        "        \"height\"          : resolution,\n",
        "        \"scale\"           : 12,\n",
        "        \"sample_steps\"    : 28,\n",
        "        \"subset\"          : [],\n",
        "    }\n",
        "}\n",
        "\n",
        "train_config = {\n",
        "    \"sdxl_arguments\": {\n",
        "        \"cache_text_encoder_outputs\" : cache_text_encoder_outputs,\n",
        "        \"no_half_vae\"                : True,\n",
        "        \"min_timestep\"               : min_timestep,\n",
        "        \"max_timestep\"               : max_timestep,\n",
        "        \"shuffle_caption\"            : True if not cache_text_encoder_outputs else False,\n",
        "        \"lowram\"                     : lowram\n",
        "    },\n",
        "    \"model_arguments\": {\n",
        "        \"pretrained_model_name_or_path\" : model_path,\n",
        "        \"vae\"                           : vae_path,\n",
        "    },\n",
        "    \"dataset_arguments\": {\n",
        "        \"debug_dataset\"                 : False,\n",
        "        \"in_json\"                       : in_json,\n",
        "        \"train_data_dir\"                : train_data_dir,\n",
        "        \"dataset_repeats\"               : num_repeats,\n",
        "        \"keep_tokens\"                   : keep_tokens,\n",
        "        \"resolution\"                    : str(resolution) + ',' + str(resolution),\n",
        "        \"color_aug\"                     : False,\n",
        "        \"face_crop_aug_range\"           : None,\n",
        "        \"token_warmup_min\"              : 1,\n",
        "        \"token_warmup_step\"             : 0,\n",
        "    },\n",
        "    \"training_arguments\": {\n",
        "        \"output_dir\"                    : os.path.join(output_dir, project_name),\n",
        "        \"output_name\"                   : project_name if project_name else \"last\",\n",
        "        \"save_precision\"                : save_precision,\n",
        "        \"save_every_n_epochs\"           : save_every_n_epochs,\n",
        "        \"save_n_epoch_ratio\"            : None,\n",
        "        \"save_last_n_epochs\"            : None,\n",
        "        \"resume\"                        : None,\n",
        "        \"train_batch_size\"              : train_batch_size,\n",
        "        \"max_token_length\"              : 225,\n",
        "        \"mem_eff_attn\"                  : False,\n",
        "        \"sdpa\"                          : True if optimization == \"scaled dot-product attention\" else False,\n",
        "        \"xformers\"                      : True if optimization == \"xformers\" else False,\n",
        "        \"max_train_epochs\"              : num_epochs,\n",
        "        \"max_data_loader_n_workers\"     : 8,\n",
        "        \"persistent_data_loader_workers\": True,\n",
        "        \"seed\"                          : seed if seed > 0 else None,\n",
        "        \"gradient_checkpointing\"        : gradient_checkpointing,\n",
        "        \"mixed_precision\"               : mixed_precision,\n",
        "    },\n",
        "    \"logging_arguments\": {\n",
        "        \"log_with\"          : \"wandb\" if wandb_api_key else \"tensorboard\",\n",
        "        \"log_tracker_name\"  : project_name if wandb_api_key and not project_name == \"last\" else None,\n",
        "        \"logging_dir\"       : logging_dir,\n",
        "        \"log_prefix\"        : project_name if not wandb_api_key else None,\n",
        "    },\n",
        "    \"sample_prompt_arguments\": {\n",
        "        \"sample_every_n_steps\"    : None,\n",
        "        \"sample_every_n_epochs\"   : save_every_n_epochs if enable_sample else None,\n",
        "        \"sample_sampler\"          : sampler,\n",
        "    },\n",
        "    \"saving_arguments\": {\n",
        "        \"save_model_as\": \"safetensors\"\n",
        "    },\n",
        "}\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "def prompt_convert(enable_sample, num_prompt, train_data_dir, prompt_config, custom_prompt):\n",
        "    if enable_sample:\n",
        "        search_pattern = os.path.join(train_data_dir, '**/*' + prompt_from_caption)\n",
        "        caption_files = glob.glob(search_pattern, recursive=True)\n",
        "\n",
        "        if not caption_files:\n",
        "            if not custom_prompt:\n",
        "                custom_prompt = \"masterpiece, best quality, 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\"\n",
        "            new_prompt_config = prompt_config.copy()\n",
        "            new_prompt_config['prompt']['subset'] = [\n",
        "                {\"prompt\": positive_prompt + custom_prompt if positive_prompt else custom_prompt}\n",
        "            ]\n",
        "        else:\n",
        "            selected_files = random.sample(caption_files, min(num_prompt, len(caption_files)))\n",
        "\n",
        "            prompts = []\n",
        "            for file in selected_files:\n",
        "                with open(file, 'r') as f:\n",
        "                    prompts.append(f.read().strip())\n",
        "\n",
        "            new_prompt_config = prompt_config.copy()\n",
        "            new_prompt_config['prompt']['subset'] = []\n",
        "\n",
        "            for prompt in prompts:\n",
        "                new_prompt = {\n",
        "                    \"prompt\": positive_prompt + prompt if positive_prompt else prompt,\n",
        "                }\n",
        "                new_prompt_config['prompt']['subset'].append(new_prompt)\n",
        "\n",
        "        return new_prompt_config\n",
        "    else:\n",
        "        return prompt_config\n",
        "\n",
        "def eliminate_none_variable(config):\n",
        "    for key in config:\n",
        "        if isinstance(config[key], dict):\n",
        "            for sub_key in config[key]:\n",
        "                if config[key][sub_key] == \"\":\n",
        "                    config[key][sub_key] = None\n",
        "        elif config[key] == \"\":\n",
        "            config[key] = None\n",
        "\n",
        "    return config\n",
        "\n",
        "try:\n",
        "    train_config.update(optimizer_config)\n",
        "except NameError:\n",
        "    raise NameError(\"'optimizer_config' dictionary is missing. Please run  '4.1. Optimizer Config' cell.\")\n",
        "\n",
        "try:\n",
        "    train_config.update(lora_config)\n",
        "except NameError:\n",
        "    raise NameError(\"'lora_config' dictionary is missing. Please run  '4.1. LoRa: Low-Rank Adaptation Config' cell.\")\n",
        "\n",
        "advanced_training_warning = False\n",
        "try:\n",
        "    train_config.update(advanced_training_config)\n",
        "except NameError:\n",
        "    advanced_training_warning = True\n",
        "    pass\n",
        "\n",
        "prompt_config = prompt_convert(enable_sample, num_prompt, train_data_dir, prompt_config, custom_prompt)\n",
        "\n",
        "config_path         = os.path.join(config_dir, \"config_file.toml\")\n",
        "prompt_path         = os.path.join(config_dir, \"sample_prompt.toml\")\n",
        "\n",
        "config_str          = toml.dumps(eliminate_none_variable(train_config))\n",
        "prompt_str          = toml.dumps(eliminate_none_variable(prompt_config))\n",
        "\n",
        "write_file(config_path, config_str)\n",
        "write_file(prompt_path, prompt_str)\n",
        "\n",
        "print(config_str)\n",
        "\n",
        "if advanced_training_warning:\n",
        "    import textwrap\n",
        "    error_message = \"WARNING: This is not an error message, but the [advanced_training_config] dictionary is missing. Please run the '4.2. Advanced Training Config' cell if you intend to use it, or continue to the next step.\"\n",
        "    wrapped_message = textwrap.fill(error_message, width=80)\n",
        "    print('\\033[38;2;204;102;102m' + wrapped_message + '\\033[0m\\n')\n",
        "    pass\n",
        "\n",
        "print(prompt_str)\n",
        "# Pseudocode for integrating the learning rate finder\n",
        "# This assumes `model` and `train_loader` are already defined\n",
        "\n",
        "# Initialize the learning rate finder here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_SHtbFwHVl1",
        "outputId": "1c7dd7a4-5a29-4bdb-ae65-304fb835e78a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading settings from /content/LoRA/config/config_file.toml...\n",
            "/content/LoRA/config/config_file\n",
            "prepare tokenizers\n",
            "update token length: 225\n",
            "Training with captions.\n",
            "loading existing metadata: /content/LoRA/meta_lat.json\n",
            "metadata has bucket info, enable bucketing / メタデータにbucket情報があるためbucketを有効にします\n",
            "using bucket info in metadata / メタデータ内のbucket情報を使います\n",
            "[Dataset 0]\n",
            "  batch_size: 4\n",
            "  resolution: (1024, 1024)\n",
            "  enable_bucket: True\n",
            "  min_bucket_reso: None\n",
            "  max_bucket_reso: None\n",
            "  bucket_reso_steps: None\n",
            "  bucket_no_upscale: None\n",
            "\n",
            "  [Subset 0 of Dataset 0]\n",
            "    image_dir: \"/content/drive/MyDrive/train/js\"\n",
            "    image_count: 58\n",
            "    num_repeats: 2\n",
            "    shuffle_caption: False\n",
            "    keep_tokens: 0\n",
            "    caption_dropout_rate: 0.0\n",
            "    caption_dropout_every_n_epoches: 0\n",
            "    caption_tag_dropout_rate: 0.0\n",
            "    color_aug: False\n",
            "    flip_aug: False\n",
            "    face_crop_aug_range: None\n",
            "    random_crop: False\n",
            "    token_warmup_min: 1,\n",
            "    token_warmup_step: 0,\n",
            "    metadata_file: /content/LoRA/meta_lat.json\n",
            "\n",
            "\n",
            "[Dataset 0]\n",
            "loading image sizes.\n",
            "100% 58/58 [00:00<00:00, 1005246.41it/s]\n",
            "make buckets\n",
            "number of images (including repeats) / 各bucketの画像枚数（繰り返し回数を含む）\n",
            "bucket 0: resolution (384, 1024), count: 2\n",
            "bucket 1: resolution (448, 1024), count: 6\n",
            "bucket 2: resolution (512, 1024), count: 2\n",
            "bucket 3: resolution (576, 1024), count: 10\n",
            "bucket 4: resolution (640, 1024), count: 2\n",
            "bucket 5: resolution (704, 1024), count: 2\n",
            "bucket 6: resolution (768, 1024), count: 48\n",
            "bucket 7: resolution (832, 1024), count: 8\n",
            "bucket 8: resolution (896, 1024), count: 2\n",
            "bucket 9: resolution (1024, 576), count: 12\n",
            "bucket 10: resolution (1024, 640), count: 2\n",
            "bucket 11: resolution (1024, 704), count: 8\n",
            "bucket 12: resolution (1024, 960), count: 4\n",
            "bucket 13: resolution (1024, 1024), count: 8\n",
            "mean ar error (without repeats): 0.0\n",
            "Warning: SDXL has been trained with noise_offset=0.0357, but noise_offset is disabled due to multires_noise_iterations / SDXLはnoise_offset=0.0357で学習されていますが、multires_noise_iterationsが有効になっているためnoise_offsetは無効になります\n",
            "preparing accelerator\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstamp-gambier0x\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "loading model for process 0/1\n",
            "load Diffusers pretrained models: stabilityai/stable-diffusion-xl-base-1.0, variant=None\n",
            "The config attributes {'add_watermarker': None} were passed to StableDiffusionXLPipeline, but are not expected and will be ignored. Please verify your model_index.json configuration file.\n",
            "Keyword arguments {'add_watermarker': None} are not expected by StableDiffusionXLPipeline and will be ignored.\n",
            "The config attributes {'force_upcast': True} were passed to AutoencoderKL, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
            "U-Net converted to original U-Net\n",
            "load VAE: /content/vae/sdxl_vae.safetensors\n",
            "additional VAE loaded\n",
            "Enable xformers for U-Net\n",
            "import network module: networks.lora\n",
            "move vae and unet to cpu to save memory\n",
            "[Dataset 0]\n",
            "caching text encoder outputs.\n",
            "checking cache existence...\n",
            "100% 58/58 [00:00<00:00, 1210296.68it/s]\n",
            "caching text encoder outputs...\n",
            "100% 15/15 [00:02<00:00,  7.09it/s]\n",
            "move vae and unet back to original device\n",
            "create LoRA network. base dim (rank): 16, alpha: 4\n",
            "neuron dropout: p=None, rank dropout: p=None, module dropout: p=None\n",
            "apply LoRA to Conv2d with kernel size (3,3). dim (rank): 8, alpha: 1.0\n",
            "create LoRA for Text Encoder 1:\n",
            "create LoRA for Text Encoder 2:\n",
            "create LoRA for Text Encoder: 264 modules.\n",
            "create LoRA for U-Net: 788 modules.\n",
            "enable LoRA for U-Net\n",
            "prepare optimizer, data loader etc.\n",
            "use Adafactor optimizer | {'relative_step': True}\n",
            "relative_step is true / relative_stepがtrueです\n",
            "override steps. steps for 12 epochs is / 指定エポックまでのステップ数: 396\n",
            "resume training from local state: /content/drive/MyDrive/kohya-trainer/output/JJS_re/JJS_re-000010-state\n"
          ]
        }
      ],
      "source": [
        "#@title ## **4.5. Start Training**\n",
        "import os\n",
        "import toml\n",
        "\n",
        "#@markdown Check your config here if you want to edit something:\n",
        "#@markdown - `sample_prompt` : /content/LoRA/config/sample_prompt.toml\n",
        "#@markdown - `config_file` : /content/LoRA/config/config_file.toml\n",
        "\n",
        "\n",
        "#@markdown You can import config from another session if you want.\n",
        "\n",
        "sample_prompt   = \"/content/LoRA/config/sample_prompt.toml\" #@param {type:'string'}\n",
        "config_file     = \"/content/LoRA/config/config_file.toml\" #@param {type:'string'}\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "def train(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    return args\n",
        "\n",
        "accelerate_conf = {\n",
        "    \"config_file\" : \"/content/kohya-trainer/accelerate_config/config.yaml\",\n",
        "    \"num_cpu_threads_per_process\" : 1,\n",
        "}\n",
        "\n",
        "train_conf = {\n",
        "    \"sample_prompts\"  : sample_prompt if os.path.exists(sample_prompt) else None,\n",
        "    \"config_file\"     : config_file,\n",
        "    \"wandb_api_key\"   : wandb_api_key if wandb_api_key else None\n",
        "}\n",
        "\n",
        "accelerate_args = train(accelerate_conf)\n",
        "train_args = train(train_conf)\n",
        "\n",
        "final_args = f\"accelerate launch {accelerate_args} sdxl_train_network.py {train_args}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}